ğŸ“° **BART-Base Summarization App**

A lightweight text summarization service using [BART-Base](https://huggingface.co/facebook/bart-base), fineâ€‘tuned on the CNN/DailyMail dataset. Includes model training, a FastAPI web app, and GPUâ€‘ready Docker deployment with load balancing.

---

## ğŸš€ Features

* ğŸ” **Abstractive summarization** using BARTâ€‘Base
* ğŸ–¥ï¸ **FastAPI** web interface with GPU acceleration
* ğŸ“¦ **Dockerized** with Nginx load balancing for scalability
* ğŸ“Š Integrated **W\&B logging**
* âš™ï¸ Configâ€‘driven training pipeline via `config.yaml`

---

## ğŸ§  Model

We use the `facebook/bart-base` model from Hugging Face, fineâ€‘tuned on the CNN/DailyMail dataset for 3 epochs with early stopping and warmâ€‘up steps.

## ğŸ—ï¸ Project Structure

```
bart-summarization/
â”œâ”€â”€ app/                  # FastAPI app
â”‚   â”œâ”€â”€ main.py           # API logic
â”‚   â”œâ”€â”€ requirements.txt  # API dependencies
â”‚   â”œâ”€â”€ Dockerfile        # Docker for FastAPI + GPU
â”‚   â”œâ”€â”€ nginx.conf        # Nginx load balancer
â”‚   â””â”€â”€ static/           # Frontend (optional)
â”‚       â””â”€â”€ index.html
â”œâ”€â”€ training/             # Training code
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ model/                # Saved BART weights & tokenizer
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ§ª Training

You can train the model using the script in `training/train.py`:

```bash
cd training
pip install -r requirements.txt
python train.py --config config.yaml
```

âœ… Logs and metrics are tracked via [Weights & Biases](https://wandb.ai/). Early stopping is applied based on validation loss.

---

## ğŸŒ Serving the Model

### Start the app locally:

```bash
docker-compose up --build
```

The summarization API will be available at [http://localhost](http://localhost).

---

## ğŸ“© API Usage

```bash
curl -X POST http://localhost/summarize \
     -H "Content-Type: application/json" \
     -d '{"text": "Your long article here..."}'
```

Returns:

```json
{ "summary": "Short summary of the input." }
```

---

## ğŸ§Š Load Balancing

**Nginx** is used as a reverse proxy to forward requests to multiple Uvicorn workers, enabling parallel handling of incoming requests.

---

## ğŸ³ Docker Notes

* The app Dockerfile is based on `nvidia/cuda` and enables GPU inference.
* The `docker-compose.yml` mounts `./model` for the FastAPI container.

---

## ğŸ“ˆ ROUGE Scores

Using `facebook/bart-base` fineâ€‘tuned on CNN/DailyMail (100000 size subsample): <br>
ROUGEâ€‘1â€¯(Fâ‚):â€¯â‰ˆâ€¯41.23 <br>
ROUGEâ€‘2â€¯(Fâ‚):â€¯â‰ˆâ€¯19.56 <br>
ROUGEâ€‘Lâ€¯(Fâ‚):â€¯â‰ˆâ€¯38.97 <br>
